{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOU_a2 (v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q1: Logistic Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x)\n",
    "  = \\dfrac{1}{\\sigma(x)} = 1+e^{-z}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "then use chain rule to calculate derivative represented by signma(x):\n",
    "$$\n",
    "\\begin{align}\n",
    "f'(x)\n",
    "= \\dfrac{d}{dz} \\biggl( \\frac{1}{\\sigma(z)} \\biggr)\n",
    "= -\\frac{\\sigma'(z)}{\\sigma(z)^2}\n",
    "\\end{align}\n",
    "$$\n",
    "then calculate derivative as usual:\n",
    "$$\n",
    "\\begin{align}\n",
    "f'(x)\n",
    "= -e^{-z}\n",
    "= 1-f(z)\n",
    "= 1 - \\frac{1}{\\sigma(z)}\n",
    "= \\frac{\\sigma(z)-1}{\\sigma(z)}\n",
    "\\end{align}\n",
    "$$\n",
    "Then we put them together to get signma'(z)\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\sigma(z)-1}{\\sigma(z)}\n",
    "=\n",
    "-\\frac{\\sigma'(z)}{\\sigma(z)^2}\n",
    "\\end{align}\n",
    "$$\n",
    "Then:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma'(z)\n",
    "=\n",
    "\\sigma(z)(1-\\sigma(z))\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q2: Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First we compute the softmax's derivative\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial y_i}{\\partial z_j} &= \\frac{\\partial\\frac{e^{z_i}}{\\sum_{k=1}^N e^{z_k}}}{\\partial z_j} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "We know the rule to find a quotient derivative is that if \n",
    "$$\n",
    "\\begin{align}\n",
    "f(x) = \\frac{g(x)}{h(x)}\n",
    "\\end{align}\n",
    "$$\n",
    "Then\n",
    "$$\n",
    "\\begin{align}\n",
    "f'(x) = \\frac{h(x)g'(x) - h'(x)g(x)}{h(x)^2}\n",
    "\\end{align}\n",
    "$$\n",
    "Using the rule to find derivative of softmax, if i == j:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial  \\frac{e^{z_i}}{\\sum_{k=1}^N e^{z_k}}}{\\partial z_j}&= \\frac{e^{z_i} \\sum_{k=1}^N e^{z_k} - e^{2z_i}}{\\left( \\sum_{k=1}^N e^{z_k}\\right)^2} \\\\\n",
    "&= \\frac{e^{z_i} \\left( \\sum_{k=1}^N e^{z_k} - e^{z_i}\\right )}{\\left( \\sum_{k=1}^N e^{z_k}\\right)^2} \\\\\n",
    "&= \\frac{ e^{z_i} }{\\sum_{k=1}^N e^{z_k} }\\frac{\\left( \\sum_{k=1}^N e^{z_k} - e^{z_i}\\right ) }{\\sum_{k=1}^N e^{z_k} } \\\\\n",
    "&= y_i(1-y_i)\\\\\n",
    "&= y_i(1-y_j)\\\\\n",
    "&= y_j(1-y_i)\\\\\n",
    "&= y_j(1-y_j)\n",
    "\\end{align}\n",
    "$$\n",
    "If i != j:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial  \\frac{e^{z_i}}{\\sum_{k=1}^N e^{z_k}}}{\\partial z_j}&= \\frac{0 - e^{z_j}e^{z_i}}{\\left( \\sum_{k=1}^N e^{z_k}\\right)^2} \\\\\n",
    "&= \\frac{- e^{z_j} }{\\sum_{k=1}^N e^{z_k} }\\frac{e^{z_i} }{\\sum_{k=1}^N e^{z_k} } \\\\\n",
    "&= - y_jy_i\n",
    "\\end{align}\n",
    "$$\n",
    "Then we see the catrgorical cross entropy loss function\n",
    "$$\n",
    "\\begin{align}\n",
    "E(\\vec{y}, \\vec{t}) &= - \\sum_i t_i log(y_i) \\\\\n",
    "\\frac{\\partial L}{\\partial z_i} &= - \\sum_k t_k \\frac{\\partial log(y_k)}{\\partial z_i } \\\\\n",
    "&= - \\sum_k t_k \\frac{\\partial log(y_k)}{\\partial y_k} \\times \\frac{\\partial y_k}{ \\partial z_i} \\\\\n",
    "&= - \\sum t_k \\frac{1}{y_k} \\times \\frac{\\partial y_k}{\\partial z_i} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Then we can plug in softmax's derivative we computed earlier:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial z_i}  &= -t_iy_i\\frac{1}{y_i}(1-y_i) - \\sum_{k\\neq i} t_k \\frac{1}{y_k}(-y_ky_i) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "extract the one that i==j, and leave the other i!=j terms to add together\n",
    "$$\n",
    "\\begin{align}\n",
    "&= -t_i(1-y_i) + \\sum_{k \\neq 1} t_ky_i \\\\\n",
    "&= - t_i + t_ip_i + \\sum_{k \\neq 1} t_ky_i \\\\\n",
    "&= y_i\\left( t_i +  \\sum_{k \\neq 1} t_k\\right) - t_i \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "note that:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{k}t_k = 1\\\\\n",
    "t_i +  \\sum_{k \\neq 1} t_k = 1\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "So we get the final solution:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial z_i} = y_i - t_i\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q3: Top-Layer Error Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(a)\n",
    "From Q1, we know that\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma'(z)\n",
    "&=  \\sigma(z)(1-\\sigma(z))\\\\\n",
    "&= y'\\\\\n",
    "&= \\frac 1 {1+e^{-z}}(1 - \\frac 1 {1+e^{-z}})\\\\\n",
    "&= \\frac {e^{-z}} {(1+e^{-z})^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E(y,t) = -t\\ln{y} - (1-t)\\ln{(1-y)}\n",
    "\\end{align}\n",
    "$$\n",
    "Then find its derivative:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac {\\partial E} {\\partial z} \n",
    "&= -t\\frac 1 {\\frac 1 {1+e^{-z}}} (\\frac {e^{-z}} {(1+e^{-z})^2}) + (1-t)\\frac 1 {1-{\\frac 1 {1+e^{-z}}}}(\\frac {e^{-z}} {(1+e^{-z})^2})\\\\\n",
    "&= -t\\frac {e^{-z}} {1+e^{-z}} + (1-t)\\frac 1 {1+{e^{-z}}}\\\\\n",
    "&= -t\\frac {e^{-z}+1} {1+e^{-z}} + \\frac 1 {1+e^{-z}}\\\\\n",
    "&= -t + \\frac 1 {1+e^{-z}}\n",
    "\\end{align}\n",
    "$$\n",
    "(b)\n",
    "$$\n",
    "\\begin{align}\n",
    "E(y,t) = y^2 - 2yt + t^2\n",
    "\\end{align}\n",
    "$$\n",
    "Then find its derivative\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac {\\partial E} {\\partial z} \n",
    "&= 2z - 2t\\\\\n",
    "&= 2z -2t\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Q4: Implementing Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Supplied Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Supplied functions\n",
    "\n",
    "def NSamples(x):\n",
    "    '''\n",
    "        n = NSamples(x)\n",
    "        \n",
    "        Returns the number of samples in a batch of inputs.\n",
    "        \n",
    "        Input:\n",
    "         x   is a 2D array\n",
    "        \n",
    "        Output:\n",
    "         n   is an integer\n",
    "    '''\n",
    "    return len(x)\n",
    "\n",
    "def Shuffle(inputs, targets):\n",
    "    '''\n",
    "        s_inputs, s_targets = Shuffle(inputs, targets)\n",
    "        \n",
    "        Randomly shuffles the dataset.\n",
    "        \n",
    "        Inputs:\n",
    "         inputs     array of inputs\n",
    "         targets    array of corresponding targets\n",
    "         \n",
    "        Outputs:\n",
    "         s_inputs   shuffled array of inputs\n",
    "         s_targets  corresponding shuffled array of targets\n",
    "    '''\n",
    "    data = list(zip(inputs,targets))\n",
    "    np.random.shuffle(data)\n",
    "    s_inputs, s_targets = zip(*data)\n",
    "    return np.array(s_inputs), np.array(s_targets)\n",
    "\n",
    "def Logistic(z):\n",
    "    '''\n",
    "        y = Logistic(z)\n",
    "\n",
    "        Applies the logistic function to each element in z.\n",
    "\n",
    "        Input:\n",
    "         z    is a scalar, list or array\n",
    "\n",
    "        Output:\n",
    "         y    is the same shape as z\n",
    "    '''\n",
    "    return 1. / (1 + np.exp(-z) )\n",
    "\n",
    "def Logistic_p(h):\n",
    "    '''\n",
    "        yp = Logistic_p(h)\n",
    "        \n",
    "        Returns the slope of the logistic function at z when h = Logistic(z).\n",
    "        Note the h is the input, NOT z.\n",
    "    '''\n",
    "    return h*(1.-h)\n",
    "\n",
    "def Identity(z):\n",
    "    '''\n",
    "        y = Identity(z)\n",
    "\n",
    "        Does nothing... simply returns z.\n",
    "\n",
    "        Input:\n",
    "         z    is a scalar, list or array\n",
    "\n",
    "        Output:\n",
    "         y    is the same shape as z\n",
    "    '''\n",
    "    return z\n",
    "\n",
    "def Identity_p(h):\n",
    "    '''\n",
    "        yp = Identity_p(h)\n",
    "        \n",
    "        Returns the slope of the identity function h.\n",
    "    '''\n",
    "    return np.ones_like(h)\n",
    "\n",
    "def OneHot(z):\n",
    "    '''\n",
    "        y = OneHot(z)\n",
    "\n",
    "        Applies the one-hot function to the vectors in z.\n",
    "        Example:\n",
    "          OneHot([[0.9, 0.1], [-0.5, 0.1]])\n",
    "          returns np.array([[1,0],[0,1]])\n",
    "\n",
    "        Input:\n",
    "         z    is a 2D array of samples\n",
    "\n",
    "        Output:\n",
    "         y    is an array the same shape as z\n",
    "    '''\n",
    "    y = []\n",
    "    # Locate the max of each row\n",
    "    for zz in z:\n",
    "        idx = np.argmax(zz)\n",
    "        b = np.zeros_like(zz)\n",
    "        b[idx] = 1.\n",
    "        y.append(b)\n",
    "    y = np.array(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \n",
    "    def __init__(self, n_nodes, act='logistic'):\n",
    "        '''\n",
    "            lyr = Layer(n_nodes, act='logistic')\n",
    "            \n",
    "            Creates a layer object.\n",
    "            \n",
    "            Inputs:\n",
    "             n_nodes  the number of nodes in the layer\n",
    "             act      specifies the activation function\n",
    "                      Use 'logistic' or 'identity'\n",
    "        '''\n",
    "        self.N = n_nodes  # number of nodes in this layer\n",
    "        self.h = []       # node activities\n",
    "        self.b = np.zeros(self.N)  # biases\n",
    "        \n",
    "        # Activation functions\n",
    "        self.sigma = Logistic\n",
    "        self.sigma_p = (lambda : Logistic_p(self.h))\n",
    "        if act=='identity':\n",
    "            self.sigma = Identity\n",
    "            self.sigma_p = (lambda : Identity_p(self.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [
     2,
     65,
     81
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Network():\n",
    "\n",
    "    def __init__(self, sizes, type='classifier'):\n",
    "        '''\n",
    "            net = Network(sizes, type='classifier')\n",
    "\n",
    "            Creates a Network and saves it in the variable 'net'.\n",
    "\n",
    "            Inputs:\n",
    "              sizes is a list of integers specifying the number\n",
    "                  of nodes in each layer\n",
    "                  eg. [5, 20, 3] will create a 3-layer network\n",
    "                      with 5 input, 20 hidden, and 3 output nodes\n",
    "              type can be either 'classifier' or 'regression', and\n",
    "                  sets the activation function on the output layer,\n",
    "                  as well as the loss function.\n",
    "                  'classifier': logistic, cross entropy\n",
    "                  'regression': linear, mean squared error\n",
    "        '''\n",
    "        self.n_layers = len(sizes)\n",
    "        self.lyr = []    # a list of Layers\n",
    "        self.W = []      # Weight matrices, indexed by the layer below it\n",
    "        \n",
    "        # Two common types of networks\n",
    "        # The member variable self.Loss refers to one of the implemented\n",
    "        # loss functions: MSE, or CrossEntropy.\n",
    "        # Call it using self.Loss(t)\n",
    "        if type=='classifier':\n",
    "            self.classifier = True\n",
    "            self.Loss = self.CrossEntropy\n",
    "            activation = 'logistic'\n",
    "        else:\n",
    "            self.classifier = False\n",
    "            self.Loss = self.MSE\n",
    "            activation = 'identity'\n",
    "\n",
    "        # Create and add Layers (using logistic for hidden layers)\n",
    "        for n in sizes[:-1]:\n",
    "            self.lyr.append( Layer(n) )\n",
    "   \n",
    "        # For the top layer, we use the appropriate activtaion function\n",
    "        self.lyr.append( Layer(sizes[-1], act=activation) )\n",
    "    \n",
    "        # Randomly initialize weight matrices\n",
    "        for idx in range(self.n_layers-1):\n",
    "            m = self.lyr[idx].N\n",
    "            n = self.lyr[idx+1].N\n",
    "            temp = np.random.normal(size=[m,n])/np.sqrt(m)\n",
    "            self.W.append(temp)\n",
    "\n",
    "\n",
    "    def FeedForward(self, x):\n",
    "        '''\n",
    "            y = net.FeedForward(x)\n",
    "\n",
    "            Runs the network forward, starting with x as input.\n",
    "            Returns the activity of the output layer.\n",
    "        '''\n",
    "        x = np.array(x)  # Convert input to array, in case it's not\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        self.lyr[0].h = x\n",
    "        for i in range(len(self.lyr)-1):\n",
    "            self.lyr[i+1].h = self.lyr[i+1].sigma((self.lyr[i].h) @ (self.W[i])+self.lyr[i+1].b)\n",
    "        return self.lyr[-1].h\n",
    "\n",
    "    \n",
    "    def Evaluate(self, inputs, targets):\n",
    "        '''\n",
    "            E = net.Evaluate(data)\n",
    "\n",
    "            Computes the average loss over the supplied dataset.\n",
    "\n",
    "            Inputs\n",
    "             inputs  is an array of inputs\n",
    "             targets is a list of corresponding targets\n",
    "\n",
    "            Outputs\n",
    "             E is a scalar, the average loss\n",
    "        '''\n",
    "        y = self.FeedForward(inputs)\n",
    "        return self.Loss(targets)\n",
    "\n",
    "    def ClassificationAccuracy(self, inputs, targets):\n",
    "        '''\n",
    "            a = net.ClassificationAccuracy(data)\n",
    "            \n",
    "            Returns the fraction (between 0 and 1) of correct one-hot classifications\n",
    "            in the dataset.\n",
    "        '''\n",
    "        y = self.FeedForward(inputs)\n",
    "        yb = OneHot(y)\n",
    "        n_incorrect = np.sum(yb!=targets) / 2.\n",
    "        return 1. - float(n_incorrect) / NSamples(inputs)\n",
    "\n",
    "    \n",
    "    def CrossEntropy(self, t):\n",
    "        '''\n",
    "            E = net.CrossEntropy(t)\n",
    "\n",
    "            Evaluates the mean cross entropy loss between t and the activity of the top layer.\n",
    "            To evaluate the network's performance on an input/output pair (x,t), use\n",
    "              net.FeedForward(x)\n",
    "              E = net.Loss(t)\n",
    "\n",
    "            Inputs:\n",
    "              t is an array holding the target output\n",
    "\n",
    "            Outputs:\n",
    "              E is the loss function for the given case\n",
    "        '''\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        E = -np.sum(t * np.log(self.lyr[-1].h) + (1.0 - t) * np.log(1 - self.lyr[-1].h)) / NSamples(t)\n",
    "        return E\n",
    "\n",
    "    \n",
    "    def MSE(self, t):\n",
    "        '''\n",
    "            E = net.MSE(t)\n",
    "\n",
    "            Evaluates the MSE loss function using t and the activity of the top layer.\n",
    "            To evaluate the network's performance on an input/output pair (x,t), use\n",
    "              net.FeedForward(x)\n",
    "              E = net.Loss(t)\n",
    "\n",
    "            Inputs:\n",
    "              t is an array holding the target output\n",
    "\n",
    "            Outputs:\n",
    "              E is the loss function for the given case\n",
    "        '''\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        E = np.sum((self.lyr[-1].h - t) ** 2) / NSamples(t)\n",
    "        return E\n",
    "\n",
    "    \n",
    "    def BackProp(self, t, lrate=0.05):\n",
    "        '''\n",
    "            net.BackProp(targets, lrate=0.05)\n",
    "            \n",
    "            Given the current network state and targets t, updates the connection\n",
    "            weights and biases using the backpropagation algorithm.\n",
    "            \n",
    "            Inputs:\n",
    "             t      an array of targets (number of samples must match the\n",
    "                    network's output)\n",
    "             lrate  learning rate\n",
    "        '''\n",
    "        t = np.array(t)  # convert t to an array, in case it's not\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        dEdz = (self.lyr[-1].h - t) / NSamples(t)\n",
    "        for i in range(self.n_layers - 2, -1, -1):\n",
    "            dEdW = (self.lyr[i].h.T) @ (dEdz)\n",
    "            dEdb = np.sum(dEdz, axis=0)\n",
    "            dEdz = dEdz @ (self.W[i].T) * self.lyr[i].sigma_p()\n",
    "            self.W[i] -= lrate * dEdW\n",
    "            self.lyr[i + 1].b -= lrate * dEdb\n",
    "\n",
    "    def Learn(self, inputs, targets, lrate=0.05, epochs=1):\n",
    "        '''\n",
    "            Network.Learn(inputs, targets, lrate=0.05, epochs=1)\n",
    "\n",
    "            Run through the dataset 'epochs' number of times, incrementing the\n",
    "            network weights for each training sample. For each epoch, it\n",
    "            shuffles the order of the samples.\n",
    "\n",
    "            Inputs:\n",
    "              inputs  is an array of input samples\n",
    "              targets is a corresponding array of targets\n",
    "              lrate   is the learning rate (try 0.001 to 0.5)\n",
    "              epochs  is the number of times to go through the training data\n",
    "        '''\n",
    "        \n",
    "        #===== YOUR CODE HERE =====\n",
    "        for k in range(epochs):\n",
    "            s_inputs, s_targets = Shuffle(inputs, targets)\n",
    "            self.FeedForward(s_inputs)\n",
    "            self.BackProp(s_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create a Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5 Classes in 8-Dimensional Space\n",
    "np.random.seed(15)\n",
    "noise = 0.1\n",
    "InputClasses = np.array([[1,0,1,0,0,1,1,0],\n",
    "                         [0,1,0,1,0,1,0,1],\n",
    "                         [0,1,1,0,1,0,0,1],\n",
    "                         [1,0,0,0,1,0,1,1],\n",
    "                         [1,0,0,1,0,1,0,1]], dtype=float)\n",
    "OutputClasses = np.array([[1,0,0,0,0],\n",
    "                          [0,1,0,0,0],\n",
    "                          [0,0,1,0,0],\n",
    "                          [0,0,0,1,0],\n",
    "                          [0,0,0,0,1]], dtype=float)\n",
    "n_input = np.shape(InputClasses)[1]\n",
    "n_output = np.shape(OutputClasses)[1]\n",
    "n_classes = np.shape(InputClasses)[0]\n",
    "\n",
    "# Create a training dataset\n",
    "n_samples = 100\n",
    "training_output = []\n",
    "training_input = []\n",
    "for idx in range(n_samples):\n",
    "    k = np.random.randint(n_classes)\n",
    "    x = InputClasses[k,:] + np.random.normal(size=n_input)*noise\n",
    "    t = OutputClasses[k,:]\n",
    "    training_input.append(x)\n",
    "    training_output.append(t)\n",
    "\n",
    "# Create a test dataset\n",
    "n_samples = 100\n",
    "test_output = []\n",
    "test_input = []\n",
    "for idx in range(n_samples):\n",
    "    k = np.random.randint(n_classes)\n",
    "    x = InputClasses[k,:] + np.random.normal(size=n_input)*noise\n",
    "    t = OutputClasses[k,:]\n",
    "    test_input.append(x)\n",
    "    test_output.append(t)\n",
    "\n",
    "train = [np.array(training_input), np.array(training_output)]\n",
    "test = [np.array(test_input), np.array(test_output)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a Network\n",
    "net = Network([n_input, 18, n_output], type='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy = 3.6170513253334455\n",
      "     Accuracy = 26.0%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate it before training\n",
    "CE = net.Evaluate(train[0], train[1])\n",
    "accuracy = net.ClassificationAccuracy(train[0], train[1])\n",
    "print('Cross Entropy = '+str(CE))\n",
    "print('     Accuracy = '+str(accuracy*100.)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net.Learn(train[0], train[1], epochs=500, lrate=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluate it After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Cross Entropy = 1.1009755976838174\n",
      "     Accuracy = 88.0%\n"
     ]
    }
   ],
   "source": [
    "print('Training Set')\n",
    "CE = net.Evaluate(train[0], train[1])\n",
    "accuracy = net.ClassificationAccuracy(train[0], train[1])\n",
    "print('Cross Entropy = '+str(CE))\n",
    "print('     Accuracy = '+str(accuracy*100.)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set\n",
      "Cross Entropy = 1.158763645124524\n",
      "     Accuracy = 86.0%\n"
     ]
    }
   ],
   "source": [
    "print('Test Set')\n",
    "CE = net.Evaluate(test[0], test[1])\n",
    "accuracy = net.ClassificationAccuracy(test[0], test[1])\n",
    "print('Cross Entropy = '+str(CE))\n",
    "print('     Accuracy = '+str(accuracy*100.)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## You can also try using the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import Network\n",
    "# importlib.reload(Network)\n",
    "# net2 = Network.Network([n_input, 18, n_output], type='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# net2.Learn(train[0], train[1], epochs=500, lrate=1.)\n",
    "# print('Training Set')\n",
    "# CE = net2.Evaluate(train[0], train[1])\n",
    "# accuracy = net2.ClassificationAccuracy(train[0], train[1])\n",
    "# print('Cross Entropy = '+str(CE))\n",
    "# print('     Accuracy = '+str(accuracy*100.)+'%')\n",
    "# print('Test Set')\n",
    "# CE = net2.Evaluate(test[0], test[1])\n",
    "# accuracy = net2.ClassificationAccuracy(test[0], test[1])\n",
    "# print('Cross Entropy = '+str(CE))\n",
    "# print('     Accuracy = '+str(accuracy*100.)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create a Regression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 1D -> 1D (linear mapping)\n",
    "np.random.seed(846)\n",
    "n_input = 1\n",
    "n_output = 1\n",
    "slope = np.random.rand() - 0.5\n",
    "intercept = np.random.rand()*2. - 1.\n",
    "\n",
    "def myfunc(x):\n",
    "    return slope*x+intercept\n",
    "\n",
    "# Create a training dataset\n",
    "n_samples = 200\n",
    "training_output = []\n",
    "training_input = []\n",
    "xv = np.linspace(-1, 1, n_samples)\n",
    "for idx in range(n_samples):\n",
    "    #x = np.random.rand()*2. - 1.\n",
    "    x = xv[idx]\n",
    "    t = myfunc(x) + np.random.normal(scale=0.1)\n",
    "    training_input.append(np.array([x]))\n",
    "    training_output.append(np.array([t]))\n",
    "\n",
    "# Create a testing dataset\n",
    "n_samples = 50\n",
    "test_input = []\n",
    "test_output = []\n",
    "xv = np.linspace(-1, 1, n_samples)\n",
    "for idx in range(n_samples):\n",
    "    #x = np.random.rand()*2. - 1.\n",
    "    x = xv[idx] + np.random.normal(scale=0.1)\n",
    "    t = myfunc(x) + np.random.normal(scale=0.1)\n",
    "    test_input.append(np.array([x]))\n",
    "    test_output.append(np.array([t]))\n",
    "\n",
    "# Create a perfect dataset\n",
    "n_samples = 100\n",
    "perfect_input = []\n",
    "perfect_output = []\n",
    "xv = np.linspace(-1, 1, n_samples)\n",
    "for idx in range(n_samples):\n",
    "    #x = np.random.rand()*2. - 1.\n",
    "    x = xv[idx]\n",
    "    t = myfunc(x)\n",
    "    perfect_input.append(np.array([x]))\n",
    "    perfect_output.append(np.array([t]))\n",
    "    \n",
    "train = [np.array(training_input), np.array(training_output)]\n",
    "test = [np.array(test_input), np.array(test_output)]\n",
    "perfect = [np.array(perfect_input), np.array(perfect_output)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = Network([1, 10, 1], type='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.35753196157541495\n"
     ]
    }
   ],
   "source": [
    "# Evaluate it before training\n",
    "mse = net.Evaluate(train[0], train[1])\n",
    "print('MSE = '+str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net.Learn(train[0], train[1], epochs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluate it After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE = 0.014130050117871615\n"
     ]
    }
   ],
   "source": [
    "# On training dataset\n",
    "mse = net.Evaluate(train[0], train[1])\n",
    "print('Training MSE = '+str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 0.017301624623795225\n"
     ]
    }
   ],
   "source": [
    "# On test dataset\n",
    "mse = net.Evaluate(test[0], test[1])\n",
    "print('Test MSE = '+str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Evaluate our model and the TRUE solution (since we know it)\n",
    "s = np.linspace(-1, 1, 200)\n",
    "y = net.FeedForward(np.array([s]).T)\n",
    "p = [myfunc(x) for x in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training data,\n",
    "# as well as out model and the true model\n",
    "plt.plot(s,y, 'r--')\n",
    "plt.plot(s,p, 'g:')\n",
    "plt.plot(training_input, training_output, 'bo')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
