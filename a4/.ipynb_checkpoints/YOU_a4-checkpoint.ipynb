{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A4: Autoencoders and RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import Network as Network\n",
    "import mnist_loader\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q1: Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Derivative of Cosine Proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Loss function is\n",
    "$$\n",
    "C ( \\vec{y} , \\vec{t} ) = \\frac{ - \\left( \\vec{y} \\cdot \\vec{t} \\right) }{ \\| \\vec{y} \\| \\ \\| \\vec{t} \\|}\n",
    "$$\n",
    "We are given that the output layer uses the identity mapping as an activation function, $\\vec{y} = \\vec{z}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial C}{\\partial {y_i}} = \\frac {\\partial \\frac{ - \\left( \\vec{y} \\cdot \\vec{t} \\right) }{ \\| \\vec{y} \\| \\ \\| \\vec{t} \\|}}{y_i}\\\\\n",
    "= -\\frac {t_i(||\\vec{y}||\\cdot ||\\vec{t}||)+\\frac {||t||\\cdot 2y_i}{2||y||} \\cdot \\vec{y} \\cdot \\vec{t} }{||\\vec y||^2 \\ ||\\vec t||^2 } \\\\\n",
    "= -\\frac {t_i}{||\\vec y|| \\ ||\\vec t||} - \\frac {y_i}{||\\vec y||^2} \\cdot C(\\vec{y},\\vec{t}) \\\\\n",
    "By\\ putting\\ all\\ y_i\\ together\\ we\\ get\\ \\frac{\\partial E}{\\partial {\\vec y}}:\\\\\n",
    "\\frac{\\partial E}{\\partial {\\vec y}} = -\\frac {\\vec t}{||\\vec y|| \\ ||\\vec t||} - \\frac {\\vec y}{||\\vec y||^2} \\cdot C(\\vec{y},\\vec{t}) \\\\\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (b) Implement Derivative of Cosine Proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cosine Proximity\n",
    "def CosineProximity(y, t):\n",
    "    '''\n",
    "        C = CosineProximity(y, t)\n",
    "        \n",
    "        Evaluates the average cosine proximity for the batch.\n",
    "        \n",
    "        Inputs:\n",
    "          y is a batch of samples, with samples stored in rows\n",
    "          t is a batch of targets\n",
    "          \n",
    "        Output:\n",
    "          C is the average cosine proximity (cost)\n",
    "    '''\n",
    "    C = -np.sum(y*t, axis=1)\n",
    "    C /= np.linalg.norm(y, axis=1)\n",
    "    C /= np.linalg.norm(t, axis=1)\n",
    "    return np.sum(C) / Network.NSamples(y)\n",
    "\n",
    "\n",
    "# CosineProximity_p\n",
    "def CosineProximity_p(y, t):\n",
    "    '''\n",
    "        dCdy = CosineProximity_p(y, t)\n",
    "        \n",
    "        Computes the gradient of the cosine proximity cost function.\n",
    "        \n",
    "        Inputs:\n",
    "          y is a batch of samples, with samples stored in rows\n",
    "          t is a batch of targets\n",
    "          \n",
    "        Output:\n",
    "          dCdy is an array the same size as y, holding the derivative\n",
    "               of the cost with respect to each element in y\n",
    "    '''\n",
    "\n",
    "    E = CosineProximity(y, t)\n",
    "    y2norm = np.linalg.norm(y, axis=1)\n",
    "    t2norm = np.linalg.norm(t, axis=1)\n",
    "    dCdy = (np.divide(t.T,(y2norm*t2norm).T)).T*(-1)-np.divide(y.T,(y2norm**2).T).T*E\n",
    "    return dCdy\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (c) Create and Train a Network\n",
    "You can make your network use your cost function and its derivative by setting the member variables,\n",
    "\n",
    "    mynet.cost = CosineProximity\n",
    "    mynet.cost_p = CosineProximity_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read in 10000 MNIST samples\n",
    "train, validate, test = mnist_loader.load_data_wrapper()\n",
    "train_in = np.array(train[0][:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxMAAACECAYAAADr0XY2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACzRJREFUeJzt3V+IVdUaAPAzppjZP8tC04k0CSENinCkCYwpouihGJzR6iEM9SEIlainHgqpILQxHwrEp6CaGYyiB1MTqYdCIxUr+kdETc70oE1G9tdo7tNdd6997zl3XJ2z55w9v9/T9/EdZ39CS/3aa63TNjY2VgEAADhbUya6AQAAoDUZJgAAgCSGCQAAIIlhAgAASGKYAAAAkhgmAACAJIYJAAAgiWECAABIMrXIh7W1tfmGvCYxNjbWNtE90BjWWfOwzsrNWmse1lp5WWfNo9o682YCAABIYpgAAACSGCYAAIAkhgkAACCJYQIAAEhimAAAAJIYJgAAgCSGCQAAIIlhAgAASGKYAAAAkhgmAACAJIYJAAAgiWECAABIMnWiGwAAmsOjjz4a5TNnzgzxE088UXA3wB133BHi3bt3R7X9+/eH+Pbbby+spzxvJgAAgCSGCQAAIIlhAgAASFLqMxPt7e1R3t/fH+JHHnkkqh08eLCQngCgWUyZEv8/xe7u7ijfs2dPke3ApHfNNddE+ZNPPhnisbGxqHbDDTeEeOHChVHt66+/bkB3/5s3EwAAQBLDBAAAkKTU25yy25oqlUpl2bJlIR4YGIhqq1atCnGjtjxln5l/VbV69eqGPBPqYcmSJVH+xRdfhPjMmTNR7d577w3xyy+/HNU++eSTEF933XV16W3t2rVRvmPHjhDn1/m6detCfPr06bo8H1rZ3XffHeUdHR1Rvm3btiLbgUmvq6srym+88caqn/30009DXOS2pjxvJgAAgCSGCQAAIIlhAgAASFLqMxM33XRTlP/9998hbmtrK7qdSk9PT4jzZyay/WTPb0AzyJ51OBv5/87zeap58+aFePv27VWf0dvbG9U2bNgQYmcmoFK5+uqra9az56OAxsufmcg6fPhwlD/00EONbmdcvJkAAACSGCYAAIAkpdvmtGnTphBntzXl8/fffz+qFfEN2NntF/ne6rX9AybafffdV7WWvyo21Z133hni6dOnR7UTJ06E+M0334xqv/32W12eD2XR2dkZ5SdPnozyoaGhItuBSenmm28O8cqVK6t+7ttvv43y1C3I9ebNBAAAkMQwAQAAJDFMAAAASUp3ZmL58uUhnjKl+qx06NChItqJZK9/zfe2bdu2otuBhpg9e3aIz5w5E9X27t1bl2fUug4vu4d0/fr1dXkelMm0adNC3NHREdUOHDgQ5aOjo4X0BJNZd3d31drw8HCIN2/eXEQ7Z82bCQAAIIlhAgAASFK6bU61rl/N5n19fYX19G+1etu4cWOIV69eXVhP8E8tWrSoav7nn39GtWPHjtXlmVOnVv+ja+fOnXV5BpTVXXfdFeK5c+dGtZGRkaLbgUkn//fmgw8+GOI//vgjqj399NMh/uijjxrbWCJvJgAAgCSGCQAAIIlhAgAASNLyZyZ6e3ujvKenJ8S1roadCLWuhr3yyitDPH/+/Kh2/PjxxjYG/0D+mtZLLrkkxEePHm348/P7S7/55puGPxMAUj377LNRfsEFF4R4x44dUe3FF18spKd/orn+tQ0AALQMwwQAAJCk5bc5Za9brVT++8rV8daKUOtq2Oy3kOa/kdQ2J5rZnDlzqtbeeuutujzjqquuivLLLrssxFu2bIlqBw8erMszYTL466+/onxwcHCCOoHyWrNmTZTfc889VT/72muvNbqduvNmAgAASGKYAAAAkhgmAACAJC1/ZmJgYCDKs+cSslexVioTf1Vsraths7V839CqLr/88ihfsmRJ0s9Zvnx51Z974YUXVn3G4sWLo1pXV1eIH3/88ag2Ojqa1Bu0muuvvz7Ep0+fjmrOHEF9ZM+/bt++Parlz/tmr4Pdv39/YxtrAG8mAACAJIYJAAAgSctvc6p1NWx+K9F4r4bNb53q6+sL8aZNm2o+P7tFKV+rdTVsttcNGzZEtV27do2nbWg6a9eurZlXczZr9+GHH47yzs7OEA8PD0e1Dz/8MMTnnnvuuHqBslm4cGGIh4aGJrATKI8ZM2ZE+e7du0N83nnnRbWvvvoqyh977LHGNVYAbyYAAIAkhgkAACCJYQIAAEjS8mcmal3/Wqu2devWqLZx48aqv27lypVVa2dzZmK8V8M+//zzFWgVe/bsifJbbrklxJdeemlUe+GFF0K8YMGCqNbe3h7iY8eORbUHHnig6vO3bNkS5Zs3bw5x/tpLmIzmz58f5d3d3SEeHBwsuh0ojew5iddffz2qzZo1K8T5q8fXr18f5T///HMDuiuONxMAAEASwwQAAJDEMAEAACRp+TMTqd8zkT0jcTa/7v/df5+tp9byvydoZi+99FLNPEX2HvxKpVJZs2ZNlGfXyKlTp6KacxIQW7RoUZRn93n/9NNPRbcDpZE9I7h06dKqn1u3bl2Uv/vuu41qaUJ4MwEAACQxTAAAAElafptTZ2dnlA8MDIQ4e9VkpTL+a2PztYMHD4Z4ZGQkqvX19VX9bF6t7VLZZ+afD5NdflsgMH6zZ8+uWnvnnXeKawRa3LXXXhvl/f39IT7//POj2nPPPRfiffv2NbaxCebNBAAAkMQwAQAAJDFMAAAASVr+zET+jMKqVatC/N5770W1WmcWtm7dGuIPPvig6jOOHz+e3Gv2OktXwwJQhPzZwqwjR44U2Am0nunTp4d4586dUS17TuLXX3+Nak899VSIf/nllwZ11xy8mQAAAJIYJgAAgCQtv80pL7sl6ZxzzpnATv7boUOHQtzR0RHVstfBDg4ORrVm+31Ao42Ojkb5559/HuWLFy8ush1oOdm/N7q7u6Nadivv0NBQYT1BK1qxYkWIly1bFtWyW5vy6+zHH39sbGNNxJsJAAAgiWECAABIYpgAAACSlO7MRDPr6+sL8SuvvBLVslfD5q+Nhcnm999/j/IffvhhgjqB1rR06dIQt7e3R7XDhw8X3Q60jCuuuCLK9+7dG+L81f1ffvlliN9+++3GNtbEvJkAAACSGCYAAIAktjlNkPw3cGevhs3XYLKZOXNmlOdfO2f19vZG+TPPPNOQngAovwULFkR5dmtTfpvTxRdfXEhPzc6/WgEAgCSGCQAAIIlhAgAASOLMxATJX//qalj4j4suuijK83tYs+bMmdPodqDlZK+Gzfv4448L7ARay2233Tbuz86aNSvEc+fOjWrff/993Xpqdt5MAAAASQwTAABAEtucCvTdd9+FeGRkJKplv6HU1bBMdidOnIjyAwcORHlXV1eIp06N/xjLXtV36tSpBnQHze+zzz4L8cmTJ6Paq6++WnQ70LKGh4dDvGvXrqj2xhtvhHgybWvK869WAAAgiWECAABIYpgAAACStOW/GryhD2trK+5hTa6/vz/Ke3p6Qpy/GnbatGl1f/7Y2Fhb3X8oTaGM6+zWW2+N8n379lX97P333x/i/DormnVWbmVca63KWisv66x5VFtn3kwAAABJDBMAAEAS25wmKa+Ey6uM62zGjBlRfvTo0RDPmzcvqq1YsSLER44caWxj/4d1Vm5lXGutylorL+usedjmBAAA1JVhAgAASGKYAAAAkjgzMUnZX1pe1lnzsM7KzVprHtZaeVlnzcOZCQAAoK4MEwAAQBLDBAAAkMQwAQAAJDFMAAAASQwTAABAkkKvhgUAAMrDmwkAACCJYQIAAEhimAAAAJIYJgAAgCSGCQAAIIlhAgAASGKYAAAAkhgmAACAJIYJAAAgiWECAABIYpgAAACSGCYAAIAkhgkAACCJYQIAAEhimAAAAJIYJgAAgCSGCQAAIIlhAgAASGKYAAAAkhgmAACAJIYJAAAgiWECAABIYpgAAACS/AvFVskTrXmXfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some sample digit images\n",
    "plt.figure(figsize=[15,4])\n",
    "n_digits = 4\n",
    "for n in range(n_digits):\n",
    "    idx = np.random.randint(10000)\n",
    "    plt.subplot(2,4,n+1)\n",
    "    plt.imshow(np.reshape(train_in[idx], [28,28]), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cost -0.8096747591287066\n"
     ]
    }
   ],
   "source": [
    "net = Network.Network()\n",
    "net.AddLayer(Network.Layer(784))\n",
    "\n",
    "net.AddLayer(Network.Layer(50, act = 'logistic'))\n",
    "net.AddLayer(Network.Layer(784, act = 'identity'))\n",
    "net.cost = CosineProximity\n",
    "net.cost_p = CosineProximity_p\n",
    "\n",
    "\n",
    "progress = net.SGD(train_in, train_in, batch_size=50, epochs=300, lrate=1.)\n",
    "\n",
    "print('training cost ' + str(net.Evaluate(train_in, train_in)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (d) View Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAADnCAYAAACaEy4gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3dvTHUX5t/GGhEDYhY1EEEIwIhIgQAFCUWrpAT898h/1WA8QS0tQwULZJgQIsjEJyB4CZAMB3oO37s61nvSdmVlZmw65Pkdd86xnbXp6etas/k73Bd9++22RJEmSJK3Xhet+A5IkSZIkL84kSZIkqQtenEmSJElSB7w4kyRJkqQOeHEmSZIkSR3w4kySJEmSOuDFmSRJkiR1wIszSZIkSerA5pW+2ObNrng9p5MnT15wNv+/e/du635O+/fvn7vub7311ma9X3DB/3/Ks1kEPp6Dxjxf67VbzzX2MUP/NwVf48CBA2fV5h9++OH6Js6mnucxpj6H/m8R73ne53vqqafOqu5//etfN+t+qA0t+jO3njurkzHtu/Ucrb+PfUzLY489dlZ1f+2119YXmFLfU47vRTxHVg9T9k/293nb3Icffjh33d90001nrPdV90E0tR9oPX7e9jzGoUOHzqrN79y50+83c3rrrbfOqu7vuuuuuep+yvHPbVlbHjrmF3FuXfT5ee/evWndO3ImSZIkSR3w4kySJEmSOrDSWOM6DQ1HLnq4UipleAh+ERGrRby3qY+Z8v4XEZ2ax1BsYmq8Z8xzj/371P+bt3/65ptvms9xLpg3Apm1t0VE/BZZhz3sj6nHb+vvtOhz51AdLaIOl7EfllUPY/qHef5+Nv+7iAj3+WLe/dezec9NF154amwo+794DM9j2WsPbR/Tv7UeM3WfLardO3ImSZIkSR3w4kySJEmSOvCdizWOGebkcGpsHxN/yYY/Y8h1zJCukckzGzP7TrYvQzYE3pMpMybSImYZ2rRpUymllIsuuqhuu/jii2uZ2+n48eO1/NVXX5VSSjl58mTd9vXXXw++Ng1FI8/WmOjCFPNGGdkeW+2VdchyZvPmzac9V+zTje9jTHRk3ZY5c9ZQX8C/j4mvRD1PjT22nntZcd9FxDcXEdtl3bbOka2/b8T222r3reOplPlnfFymRUfAs79HPbF8ySWX1G2XXnpp87Hsv48dO1bL0e9/+eWXzcfSlLrstT8aY0ykOspZm8/6afblsX1dtwYs07wRfm7L2uHQ62Xn2VbdZ3jsLKPdO3ImSZIkSR34zoyctX5NaP3qlpWz0Rj+0sGr7dZ2XsWP+aX+uzIJyZT33qrn7FdTbs/2X+s5snrtaURt3l/Sh9p51uYvu+yyWr766qtLKaVcddVVdRvL9Omnn9byhx9+WMsfffRRKWX2F1aa8svqsn4VHPp1et7JECj7nOwrhvoC/iIdI5Ib8Re9LVu2lFJmRzv5PuYdLVvWL7JT1kyiKftkynGe7Y8xI/WtpMWY5+7JIvZzVlfZyEBsZztlW89+yY62ztfhsUA9TEJ0JmNGW6h1Tssey76eo2TRr1933XV1W/T/pczug08++aSW2e/HPsv6tDGTNfR6LIzRGgGjrM1HvbHNZ3XY6t+5fcwI8brMO2qU9bFDk1gNfQ8vZfZ4aOE5dyiVxX0ztU23HjM0IlcfN+pRkiRJkqSl8uJMkiRJkjrQbaxxzPBhawiSkxls3bq1lhnruvzyy2v5iiuuOO3vWYSOw82MA0TE63//+1/dxogAJ1LIhmTPNa34TvZ5OCzcil/EPthY5v5jhItD0hG1+/jjj+s21ve64xRT1sgY815Zl1Fmu2zFF0spZceOHbW8a9euUkopN954Y93GWOPnn39ey//9739red++fbUcdcxYYxbfaE3AQ6uIvyz6ht1WnHHMxB6tGC7b8xdffHHaY0uZbf+xPYuwZtGRof2wimNlyv4fahdjYuStx/DvPF+wzGOKEyhEn8T+/8SJE7XM7XztoYlHFln3UyJ9U9f6a8U62fayyGF8ftZDqy/b+Hw8B8R21iuPHe4Hbm9FyZYRe1xEPzY0iVEWheN584c//GEt/+QnPymllLJz5866jfX71ltv1TLr7OjRo7Uc5xT+H/uprM1nn2vjZ+rRUDw56+v53SPK2T7LJnFqTRSSHWNZnz5lfcdFyuKJYUzkns/RitRm59bWpGZ8LNs0+wr279dee20tX3PNNaWU2fpmu+d3n6y/ifc/zz5w5EySJEmSOuDFmSRJkiR1oKtY45h4SxbTiRgKI4vbtm2r5RiiLGV25qLvf//7pZRSrrzyyuZrMCbGIU8O5b/xxhullFJeffXVuu3NN9+s5Yg9lpJHYGIotOeo41BcaMyaE62hfNbx7t27a/nmm29uvh6jdjG0zJkEs+joOob6p8wyl7XtLL4WsVC2c7btW265pZZvu+22Wv7xj39cSpk9JlhPjIiy3j/44INafuedd0ops/WexUmzz9JaM2pZ6z0tOkoW7531k0Xh2CdF1JQRDMYj2D9kUa94zGeffVa3MbLBfiX7jK26X0XMaN617VrtojVr68Yy63nKOlmMOPI4if3KPob9O+Ps3CdDcZ9FmjJr4Zjjje0w6oX1yugh2zpnDYz/Y33znMt+i8/BfRz9C+v7vffeq2X2RUeOHDnt/0o5dayNWU9wqnkj7GNmu4wy+xi2y9tvv72W77333lq+4447SimzEXfW36FDh2qZcXbWT5yfeZ7m8cH+i7Ev9o2teFcPMw1mx39rxu5sTU/WG+Nt8RzZLTU8Pvh6WVS39dosZ+eLVWq16ykzMZ5pe+BnYx+yffv2Wo7+hO+HbZN1zP3wgx/8oJZvuumm097P+++/X8v8Hvruu+/WMttDaz3YsRw5kyRJkqQOeHEmSZIkSR3oKtY4dRFeDvFHtCKLWDA2waHLG264oZQyO1TKWBDjAIzZcSg0ZkrKYjaMgDBSwOHP1mxMvc1mlL23GLLl0G02mxeHtWNInrG8H/3oR7XMiCOjdozXxfB0NlNXFglclaF9OKadM67Adhf1xuF8RhkjvljKqVm7Sjk1XM92zrbI12NsgLHe733ve6WU2RlKic/dikVlljVr3ZTHZouftz4Ht3HGy+hXSplt09H3MPbIttuKRJQyG2GMGdYYq8gW9GXspTUL1tAMjqs25XhgHXK2umibpczOUhrHC+uE0UNGEvkY7td4Te4n7j/uJxqKMq5iAfApf8/OX1HOZjjjeZbbo9/ic8UtBaXMzjDI8wHFwsgHDx6s23j7wOHDh2v57bffrmXu19askYuKmQ4tTJ5F+rK+p9UPMcrI8+PPf/7zWn7ooYdqOWbk5fcO1hO387zK/iS+9zCex+9erQWrS5k9tqI99fCdJnsP/EytGbtb/Wcps/uE3zmvv/76Uspsf8TjinFb9idxy0App/ZJ63tTKePicq32twpD7b712I2Pib6e+4P9ccR2Synlvvvuq+Vos+yP+R2SEWjWLfukeA7uM8YXee7nd04+X8Srna1RkiRJks5RXpxJkiRJUge6ijVOnb2lNVzKoWlGXRi3YDwxohccguewMaMZMUxdSnvRVw5zZrNGxsyOpcwOkcaQazZ8vUpjFnRtlfneuR8YxWtF9BgBu/POO2uZsbzXXnutlvk6sd8Yw6BsNqZlLEI6RWvIP4uYMQrIuozIIWONjOwy0sV2HLMWMRbHGBBfj7FGtv+YtYjPwYhMFrdY1yxSU2YHbM0oWcpsZDr6FkZW2F7vuuuuWmasMfoFzhzFuEU2yxzjYFH32YKeWZtapaHjK+tjhuItpZyqe7Z1LrLLqAu3R52zD2a/n8WHGaOJ7dnMX1m8uhWdyxahPVtDC3mPiTLyOGV/ENE2RrkiJl3KbFtnv96aKZPnYUb0WN+MJUUUicfhmEV9WfdxTHGGwUUZ2odTz6usq+g3WGeML/7qV7+qZfb70daffvrpuu3555+v5RdeeKGWGVHnPm+d34dir6XMtv/W+XmVEccx53t+Z2l972N/w1gvjwXWfUTk+FjWCeOLr7/+erP8yiuvlFJmo6M8RyyjHU+VnVtbUdZsn2fnqTim2Sfs2bOnlh955JFaZqwxjvO9e/fWbaw39iuM67Jviddku+D3Gr4nXmswRt36XGPbvSNnkiRJktQBL84kSZIkqQNdxRrnXYy0lFPD8BxC5hAzh0IZdYlhUy4ux/fB4W0+N0X0i1EYDpUyDpDNHtPTbEY0tCgmMdLAOBwjnny+GBbm/mBsg0PFnM2IC2dGNIBD1twPY2blirpfRgRszOxEQ7JoXbQxbmMciW1t3759tRwznDHSwvqNGb5KKeWee+6pZUb4IuKRzayW1fu8s8etUhbvYvuOtsv2yoVgGXHk54+F6hld4X5irIl9CEVfx7gFy2MiU2HV9R2vl8XOKIuXRpvjzKTs3xmRY78Q0a5//vOfdRsjKNy/PHcwNhzvlXFIRosYW1pXW57yulkds92zbUVfzogz2zrrnrcSRB2xfti+eW5lf8YYUbxX7qdsBsExsyGuSquvz2bc43Z+zjgXso958MEHa5mzzLFveeyxx0oppfz73/+u2zjDJRfxZlSX597WjMhsH9nMsyxHvfPzLeu7Tut2lyzWyO8K/K5366231nKcA7mNj2XckW0wPj/rlVF19it8f63vL4xiZ3HRKbHaRfZN2evGex9zW1L2HSHOdfxO8sADD9Qybx/gcfTss8+WUkp59NFH67aXXnqp+Rp8Dp7PW7dgsL6z8qLatSNnkiRJktSBrkbOxuAvfbxpNX5Nve222+q2+++/v5Y5AsBf5mIdCf76yV98+KsQX5sjDXEVztEivrdsDTX+ihLldfyyN1a2XkV8Pv6Kybrg52e9RR3xFyTeZMmbYOPG2FJmb/KMNW/4ixV/ccy0fk1dxsjZ0K8o2f7O1lThr0PRTllPvMk41sMqZfZm75dffrmUMvsLKkc3+dq8wZ/7KfYvj49snb8eJqWgoV8Ns/femhiBo4n8NZWj4vzVOspcU4h1z1/AOTLEem6tGcX2zz5maG2ldU2MM/XXRX6+qCO2Ta6TxT6Gv5z+7ne/K6WcGr0sZXa0iL+M8/l4w3/8as3jtjW6U0p+PCy7j8/2aZTHTAjCtt4awWFfwIk/uJ2fP0ZoeFywX+MIPEcl+fiYfIjHDvs7jgIxCcM1jeK5s0TIMkR9Z6NG2UQbbPMxUskRYvYPHAF+4oknavlvf/tbKWW2njiazL6C52y2+XhPPFbYH2XHAr/fxHGzrknOsnVXs76XfUvUeTaqwjb6n//8p5bjOwv7Ix5LPHdwJJqv0zrHs52PWUMs6nwVI5Wtvid73TFtIfobtnX203yOJ598spb/8Ic/lFJK+etf/1q3sd442sk1YHkMRLvnMcLn4HcqHn+8lojjYZ7zrCNnkiRJktQBL84kSZIkqQNdxBqH4hbZkDRvWo0YCqOMvGH26quvrmUOR8bNs7yJljg0n63pFM/NiS04vJ/dwMlyDM9OWY9pFRhl4BAy90M8hrFG3tTKCQ84/BsxAkYoGOXg2mac0IL7KoaQ2Rb42mMm5FjnOmfZunbczrrmkHnUJdsa2zZvRG6tacZ4C6NJxBgGoyytY5bvk9HhLCa47HofE/kYemwWU4vPx8/J+mYb/dOf/lTLESXl/zFKwTpm7IXHYUS2GL9mGxizrkxYRduf90Z19gXsI3bt2lVKmY3/sJ+OKFcppfz+97+v5eeee66UMrufskg1Y02cHCRi1Hw99uM9xNIXMekO+yI+Ptot+9tsUiCeI+N44Lbs9gH231x/Mfo29ltcK5SPZZSR+ztbD3PRho7BrM2zj2G/EJOucA0/RvIYYWff0+or2KezX+H5m+X4X74e/57VaWuik3V9p8nOQdkkbpzMJr7fMW7LaDTXjeN6cjGJB1+PfTpvtWFsj/0a227I4rFT1wlelDHrVA5hv8l9EvXFOuF5gbe7PP7447Uctw/w+xD/j/uBt0Kx34/2wH3NW0EOHz5cy1lUeGiNzzNx5EySJEmSOuDFmSRJkiR1oItYY0s21M/4w0033VTLsVYBo4wcoow4SimlvPjii7X8zDPPlFJmZ2Hha3AImTPmsByRymzdiizqMiV+tEpTo5WtdZcYachmsomoEvcjn4P7hOt88DkiUsPYE4fF+T5Y7mE9rY2yNsM2yDhVRFL4f/w7Z4nisHvUA2dkY0yJsw4y3tGqV7437rsp8a5lRUyHZpEa83+M/fDzRx/Bv3MWOcZwOVNaRCW4bgtnjmK8lDEixrRidrDsuMpmf6OhmbQWaag/yeqbMSPWV8QaWT8xA2kppfz973+vZfYbURds04wssh/i6zGCGhGvLMYyZlbGdfc92bHAY5n7geU4xrlvWD/EWezi2GBMi2XOrsh+mmtaRntnTJ7/x+OPfV8W+V2moTjTmNkDGeWKOCNvnWC9s64Z5Yp+g/uW8V32+9zeiu2y/2Pkkn0P28qYNUaXoVXPY24fyCL88Xz8DvnUU0/V8h//+MdaZgSuFQflazMmye+O0b+VcurWDsZSuW/4WbO6D8vqd7J+Y944O9t1xA8Zneb3Qs6EzHNAHP+8nYl9+kMPPVTL//d//1fLjDhGPHj//v11G9dK43md+4fO5nYlR84kSZIkqQNenEmSJElSB7qINU6JunCYkjPc3H333aWU2QXl+LxcHDBm7SqllAMHDpzxtRlf5MxQjITFsDWHYzn0nC2211oIs4d447xxSz6WsRLGV1hvESNinIh1xRgBY12MHMRwN2M23H+MtPSkFTHIZgnMRH0zVsXPO2VmUMZUGLNjBKw1a2QWyeH27D2ta4bSof4m296Kd/G5GFNhxJMzrEV7ZYSIUUZGSrPFLyNOwXgXZ4Ql7odVmhIdzRY/ZntiJCUWbOVzcBYt9tPsF2LGOz4v40R8DZ5nWLcRH+O+zvr3rB+d0v7O1tCisGP6eu6T6HuzGUbZ3ngMRH2yfWezPLJu2cYjttiK+G58LPdZNrvdqrRmth0zKym/30TbZL/Bz8X4J2NYcSxwdjr26XwNRhw5E13031z8l++Dxxv7yB5mno7XzeK72aykrVs0+F2QM0lni0JH+2ZckvWWLTzN+Gi0b0Z2s9kx1zVTbPZdJbZnfQzbCp+D7TD6bx7PjKpzFmr2U9Gu2Y8zsvjb3/62ln/605/WMvuQuP2J0Ul+J2U/xffPz9XiItSSJEmSdA7x4kySJEmSOrC2WOOU2dMYF4yFi0s5NUtiKadmMeIQMqMuXKyOQ5MRv+NQMt8bZ+XijCwcLm3NKJMN5WYzBfUkiwAMYf1wyJexNg7rx9AzIwSMrDCKypgoh70jUjM1QrGORahb7zGb3Y1D9HwM6yqOC/6d+4v7g+V4DPcFZ4hiNJjtnNEK7o/ACBnfEx+bzZq1DIuI0mT7J9o0X4P91J49e2qZ/ULUUdb+eNy0ooylnIq6ZDOR8j1zeytuseroUStal80MyOO8NRtr1r4ZVWSEK/oKniNYZsSLsT1GXSLaxJhNNivdvJHwRRrq27IZYrNFe2P/ML6YnccYYYx65mP5HCxndRuzNTLKyPj8mIXBWzG3dfT/bOfsN9heGS+P9s//47mS0UK213g8I7v33XdfLd9+++3N/+PxFDFgzn7N98F9wPMTtWZNXEW9t24X4bmV5yC2GbalaI/sS9lvcD/x+2nrdhf2Yzznsq9j+47vqvweyuMji62vMkaa7cehY43vkZ+DdRv7hN/ZuZA9n+POO++s5eh7eC5g++Ws7my/TzzxRC3/5S9/KaXMfg/lfiC+/0VF2B05kyRJkqQOrG3kbOjqkb/MZDfPcyKJ+OWBv+7zxti33nqrlvkLSVyl82qdr83JLHgVzPcUv4bwxmj+CtX6xb2U5Y8cLFNrRIHrnWQ3Z7OO4ldC/h9HO/mLBZ+jdSNpNjpJ67wZPHv9bGKEMev8xa9CHPVlXRIfE22dv5r+5je/qeV77rmnltlesxvxQ7bOGcvZxBXL1hqpGvMLVjaZSfyKz5vE2Tfx5nmuTRSvyfrjWk18Po6itUYFsl/oshGQockhFmnoebPjojXpysbt8flYJxzhjTUvS5n91TrafbYmDfcTf+FmXxb7hM8xZoKNKfWxbNmobTZa1ppgiWvscV0tjjhyNCBGj9k/cf9mEwux39r4HkqZPSbZt2Sjb612v45157IJEDjayEk8ov74Kz9HE1jmcRF90r333lu3/eIXv6hl7oOnn366llln8V2Hxxj/no2WDVnXJCHZaBn7Xrbv+A7IETdO4ME+ho+JlEQ2KRn3O9srExPxfZb7dMzEYa2+Z9XtfGj/sk/n9+9WkoR1wvMiv4fff//9tRypOqZW2H7Zpz/55JO1/Oijj9ZyrGnGYy5b020oBTc0SUiLI2eSJEmS1AEvziRJkiSpA12sc9Yabs3W/uDNl4wAxLDw22+/Xbft27evlhmR4/B14LBjdmMoh6w5JB1Dq3zPHP5klCObKKNX2YQIFHXPoXnWMeuT9RYRGEaEGM/gvmxNQMH3lA2hs47XEWXJ3tdQrIz1zmgPbxiPWGK2Thyjc4wNxfHE6B1vpuV74jHENUUi9sHHZusd8THZfly21k3JY9oM2yZvRI42zbbNx3KfcZ/E5+dzZZO4ZGunTGm72TE7T8xiiinvMbthnO+dMZSIuLDu2fZ4PDByFPEURtWztf4Yl+FkLK0JBrIIbzY5yJRY7Tyyfm7oBv1svTmK/fD666/XbbyVgPXG83O0ce4z/p2RYMYaGUWK7dlkJDz/8HWyiThWbcyEIPzs3B71x/XH/vWvf9Xyq6++Wsusn5iY6Gc/+1ndxkjeP/7xj1p+4YUXmu871ofiMZZNvsJyr9G67LsZ2zHXv43jgvXKds5jhW0wziOMxfEY42vz/9jXRT2PmcAm6+uXXedZRL11y0l2u0Y2CV3UXfY9g2uIMroba8jxNTiZR6xhVsrsJCDPPPNMLcd3WD5H1i9mog7mmXjLkTNJkiRJ6oAXZ5IkSZLUgS5ijYFDf4wFMf7AdSQ4vBkxq5dffrlu4zA943KtdSIYn+CQPSNOXMeJs8DE+2OskdEZRpg4CxCHb9c1c9G8WkPo2cxZjGdwrYmI6HGomLENxgEY92qt7ZHFobL3nM1GtmjZcPaUmRsZt+J6NRFrjNjJxv9jO+axEtEZxoX5GtksYNw30Y5Zp4zqZJGFIatc+ybbxuOSxz9jERG55UyLjJEykssoczwH+7fdu3fXMvsV1i1ns4r/zeIWfM9DMzeuur6HIqV8P+xPGDkK7BPY1lkvrVkF2aZ5DHC/Z2uhtWIqlK3jl82qFta1LlG2vlA2A12c13gs8PkYW2c59hVje5wtlusR8fXYb0Uflc0OmM2E3IoHr3p9v42yvpKfnZ8z2jdnM967d28t8/jYsWNHLcfMjFzbjMfEs88+W8u89YNryMY+Y/vIZu5lu2jdtrHqum71N1mskX05Y2/x+dg3Z7cPcL25iMWxHhjf5XfELIYbbWNMrHHou8YqYtTzPpbHAOs26ojHAmcxZUSXx058d2S9clZZzt7Odt+ahZrvLVtDdChSOk+7d+RMkiRJkjrgxZkkSZIkdaCLWGMM+XGonxFCzlDHqASHP2NYn0OUnF2O0aKhGXz4PhjDiBlgSpkdTo3HMC7AGb441M330esi1FkEZ2ihPdYrh5i5uCtn14ntjBZwFrBsIe/WTICsyyyWto6I15j4Vgtjb9kipRHz4bGSLY7Lzx5tMJuVkO2YMRXuj/jfbBbBbGHhVsSoh+NgzKLZjNlG3CI7nhlrbC0szegR+zfGMLKFXmO/8/1ks6SNicAsW+u1xrw+o4rsT6NuWfesK/Y93CfxHIy3sG/ifsriia3ZusZEGddd39zOv/PzZLNV8hwY7YzxH+4HtlP2YVEXbOs8h2aLU7ciXlm0KOtHWvWxjHjd0D4eE+miVqSa9c72yvgnbx2I2a35XIxG8pYL3jKya9euWo44H2N4hw4dqmXG3bNYYxwj61jw+0yvy/fI/pR9T8QdeRzwvMA65DmyhccK9182q3QcC4yU8n22ZkfcaF23zAx9rxoTDY9jg9+BGEVnfTKiG31BNrMrrw24z1iHcUyxP8rOz1NmAh97DDhyJkmSJEkd8OJMkiRJkjrQRawxhvkYf2rNLrexzMfH0CSHfLNFo1uLQXImnmxBTM6Kd8stt9RyDG9mM8AwRsP4RmtYdF3D/pTN5kVZlCewPllXjEvEPmFdZQtPZzNaxXvNInrcni2ovcyFSYdmBeN7ymZOYzyIj4kh9mzWpywWGo9pbStltv6yoftW3ICfNZvNbWjWqd5mLWX7YR1Fm+ffuR8YWWFdRNtlm2ObZ//ACFhrNlnOmJYdj4xk8DXX3d9kM5MSo0OM2kYdsa/nY9k/MPYSi1ezX+EsgWz3LLM+W4uPj4ky9tSv8z224rKlzJ4DeS6ONsd2zzpm3bLcOs9mfU5Wh9HGx+ynrH2tKsI+ZTbIrB7YvlnHgX0C47ls03FcsA9iX8EIJOPxXMg99h2/37z22mu1nPVfPCbX3f7HLLyexWKj7ng+5b7JYnFx3ub+52OzfdJqr5S181b/Tss6t06J9FH23tl/x/dvztDI70BcfD3691JOHVPsb/gafCzrm5HJ6Pf4+XgeymYAzb4zt/7vTBw5kyRJkqQOeHEmSZIkSR3oNtaYRbw4TNmatYUzQFE2hBxDjJyJkQsw8jVi5qON7zVieVz0OlvYLpuVZ93D/pQNN1Mr1sPHchiakQvWc8ReODTNOBiHm7PFOeMxjFAMLQjYk2zmtKzeW5HNMXFIPnfEUPhcPD6yGYm4MG3EDfgajLSwzXPfDC28vsh9NCVaxLbWmlGylNk6jHph3WdRF37+6EP43jgTIV+Pi/QyPtqaEYz9SjY7Jq37WMhiRqxj7rNWf8O/Z22P2+MckS22zLriscFIWZTH9DFDs6etOsIbr5fFGjlDI2cT5faIvmUz22Xnt9ivWcyWxxHLfL5o99wf2eK9PcVLWwvRsv2wjXLmPy6KHBHGbFZG9g8898a+49/5f3ws+2bu04iAcSZlztDIqBf/r3WMrKvfyb5rZRG0Vtt/5wjBAAAWMElEQVTkZ2MbZP/emqE0O+dlMwTP2y9k7Tyee1n9Tfa6rddjvbLMPpn9zY033lhKmW2n3A+cdZHn0TimeL3AfcPX5m033FexX3n7AGUzvGf9/lSOnEmSJElSB7oYOQu86s7WF+LVOK+Ko8zRLa4vxl+b+ctqXIXzJlqO7mS/4nFk7KWXXiqllPLiiy/WbVwH5Fxe22zMr0yxT/irHn+N4AgARyLjV0LWFX8V4a8p2S+r8avQmPXMxvyyumpjftXlL6v8lTKOC35etl3+WspfZONmbh4H2aQibLt8vtg3bM98b9kkAWPWJVq21i/ZWfvnr23UOhb4+WPdxVJmb7SPMkeIWCdca4gj+K21+7JfqbNRwCHrOg6yX1OH9gn3H9sv64VtOfYZJ3niOYSfn8cGfznlc7f+L7PKUbLstYbaAv/OySY4iVNMFMI2zV+1sxvmY4SSE00w5ZKtXcR+K/YJvw9kEz5NGS1b5fqWLa01tUqZXY8szq2cJIh9E7ezfce+Yb1ztJiv98orr9Qyv9/E+YLbOErB99/r95sx+2NoIgfK2lc2UU7gccP9lz1HyEaZ+bl6mEyr9X6y/p3nQNYLv8PH90iOprHN8jqB59z4zsS65Hd89ml8bfb1kTDiOSTrb2hosjnXOZMkSZKkc4gXZ5IkSZLUgS5ijTH8ySFDTgzB4X0OvTNOsXv37lLKbISOQ+wc8uSNrTFEyiFWDhszVnHw4MFaPnDgQC3HsD/XAeH7z26S7gmHYls3k5aST1gRw/PXXntt3ZatCce6jfrkOimsq6Eo48bHt95bFmVc1E2bQ4b2d3aDMIfr2ZYYAY3heN5kn0Uz3njjjVrev39/KWV2rQ/uW8ZeOKRPES3iRCKMEWc3ibf2Fy3y+MieqzUhQ7ZOCaO1rKPYzjgd/84YBiNFd99992l/5/89+OCDtcy1pjhpTkQvGO/K1subEulaVt23XiN7rSye2bqZm8c522F2DMRz8LzBOB3bJtembK2fQ9n6iVPqcxWR0ng/WT/D+DSPWcbVY3In9umMuHGiiFYEKIvt8hjgeZTn3NgPPObGRJOX1cbPBt9HtrYZz4vxeEawsklpGBeNfo3HD/s6Tqjw9NNP1/LevXtrOfp1HmPZpCzZ94h1y86z2RqFrT6Ux0H2vajVHvlcPG5a69GVMlu3rbUJs3rNPuO62vzQ/mf/zfMhb82IcyDj58S1GdnGo01yn/G44KQ4bL885uLaILutasx3yNYtFK5zJkmSJEnnEC/OJEmSJKkDXcQaA4cXGeVilJHDtZyBMYbc9+zZU7cxvsJhY87IwphYYKSDkUrGLRjfiGH/bG2jHoaYp8hmXMrWP4sYHGf4YlyIn5kxlZdffrmUMhs5zWIGWRwu6nZMpKWnmEVg3WQzPbE9MnoUbZ5tkTNqcZg/ooylnJpdlHXNIX/GClhnfB8RW2R8kbEXvk/GdlpRnN7W+8uidYx7Rt1yG+uN9fnAAw/UcsQWua9Zr5xpjXE6RrG5PTDammnV8yr6o6HXZV2w38w+U8SI2H7Z1tnvM5YaEZdsxjTOApatWRfvn1GmMWssUnz2VbT11mtka2zx80dUv5TZuHprVmTGb3lbAfdrRBGz9RsZu2akjtvjvJ2tbUZZu249fh3n5Kz9s69szczLNs92yf+74447ajn6k2zG0WeffbaWn3vuuVpmW4jnzmZE5Xua0qZ76OuzW07Y77dm2OXMxdltIK1IKaO8fCxvCWDfE6/JeB7POTx+M+uONWbf6cbEjeOzsg7ZpzPWyMh09Fnsm2699dbTnreU2e9PjPnGMcO2PmYdy1Z7mKetO3ImSZIkSR3w4kySJEmSOtBFrLE1gxeHEjlzFofyOUtUxA8Zq+DCjPw/Dl1GpI6vzUgZh5tZbi1kPWYBxnMh1kj8TNmMdhxyDxyaZ0SGw/CxHxhrZDyDcSHia8fQcm/RuDAUu8lmTmOZn601eygjb4wEcfifsZbYN5whiW2e+4Pvg68dx1M2E2M2E2LLsmZTG6r7Me0k2z/xv6xDRlZ++ctf1vIjjzxSy/F4xrUY246obymz/Rv3cRwjjP1l7YVWeVxMeS2+32z2wNYirWxvrfhiKbMx0XgO9jE8Lhh1YUS7FcvJ4nlZxKkVr17WuWCo7vm+GBHkOY1tks8X+4eLuDL2yDbJPiXqOVvcm3F33kqQLXYcFlGHyz4uhmZsyyLOrT6U9ccy2z9nAYxZpRmFZpm3avB7VutcxPc55rvOUL++yu9CU2bWK2U4nsj6ZpmvE/+XzRLN2CrbeSteydfIonVDMyGvQmufZgtss63z+yLrJSKHvM2Jf+dz87aC6J/Zp/MaIOvr+B0/3t/ZfLdsHfsuQi1JkiRJ5xAvziRJkiSpA13EGls4DJjN4sjYRAx/Pv74483nyGYXiuFiRmE49MqhUM5WlC3OG6YucrzK2dMWge8z4kccEua+yWbYjP/LokyUxYhCT1HGMYb2d7agZKvMts3h+myh09jO/8sWkOb/8fGxz8bMTkdDsYdlGTqusuM1W/A8orX8O/uQbBbAiCcyfsoyI6VZpDLeaxaXGTM77LLrfKi+s8hTa4a/UtqRNn5mxuk4q1prBtQs/sOYHc8Rrah11u6nxFd6aPf8HKxjtsMXX3yxliP6xtl42e5Z961jh3XJc0QWOeJjYp+cK+fI0Hq/2THK7a12x/gX+wS2V0ZEW+2U51h+j+Hz8RiJ58himWPafE/fb7K+PluEOrCOs/MCv6e0PivrnscYF1luLTTO99O6rWPje1oXvp+hfc32xqgt22R8r2edZNHpVptkn85ZGbkf+Nrc3pppcWr7HZqx8kwcOZMkSZKkDnhxJkmSJEkd6DbWSNnsNK3oIyNZ2ex3fL6IH2WzznGINZuNLp7vbGIqPQz3T9H6rNnCw1lssRUvGrNg4blk3lhZ1uZbC/NmcQy2XT6mFRHlfsmOm1akcurna0UEltX256377P/YXqPMOBZnmWMk789//vNp2xmlYFSbsTDGxXhctKJ1i4i0rGKmzCmvy/bLcjyebTrrp1sLLrP9Z3069yvrPp6j9X5KyWd8o3XNmtmapTSL1GXnw6gXtnXKorbRL2XxdL7GlAXsM+fS+WJolsBSTrU3bmNdcjY/PobRuZAdH2Oiuq33vKzZdlchayeteslmGsyOlfg/RtzZb4yJKsbtBuyPsv23LlNm5eRj2U4Z1+UxH7cEZDFS1n2rPrmNxwhltyu1vp9MiW3yMUO35bQ4ciZJkiRJHTgnRs4yU37J5y/SrRsHx/zySq1fjs6lX+sWKeorW/skWx+l9Usuf2H4LtTnlLW2po70tOo7Wyen9Yt2NmFI631ONeazrGv/TpmsIhvJjX6BI4tcJyibmKU1GcvQ5BMbnyMen436TLHqX7qHfoUfM5lJq08eM7FB1Bt/TWXdc59kv7LGa/P1sn6vtxGFKeufUavtTT2O4zGs+2yUKJt4YZGjBOteF3NMm2+dF7luE9soz5usP44KDL3GmHLrOTJDo7Y9GJOSCNxPbMetREX2f9kIMUc4W+eDI0eO1G3sp3oYOcsmhwljvr+0kiGZofoupT1y1ppUqpS8j5myNl/W17dSHmPPBY6cSZIkSVIHvDiTJEmSpA6cE7HGVqyilNmhxKGh0ExrvbKeI1m9GDO0PGTqWnDnuinD5JQNmbduMs3WWWnFH6auVZO9pyFTYg89xL+I9dmqb77fbCKV7PGtbdnajIuul2XX85T2NDXOO7QfqBXnzSImi+jTxkTGhv7vbM37XGOidq16WcS5cExfNO8aietYW3HKJAnZ/7EcE0ExyriIOpsycdMYY55vnuddhaw+oy/PYuZDty5k66Blceiheumt3qjVt05tS0OPzyZAa32fbE0aeKbXY783ZS3a7BaSs1nf7/z6dixJkiRJnfLiTJIkSZI6cEHPQ6SSJEmSdL5w5EySJEmSOuDFmSRJkiR1wIszSZIkSeqAF2eSJEmS1AEvziRJkiSpA16cSZIkSVIHvDiTJEmSpA54cSZJkiRJHfDiTJIkSZI64MWZJEmSJHXAizNJkiRJ6oAXZ5IkSZLUAS/OJEmSJKkDXpxJkiRJUge8OJMkSZKkDnhxJkmSJEkd8OJMkiRJkjrgxZkkSZIkdcCLM0mSJEnqgBdnkiRJktQBL84kSZIkqQNenEmSJElSB7w4kyRJkqQOeHEmSZIkSR3w4kySJEmSOuDFmSRJkiR1wIszSZIkSeqAF2eSJEmS1AEvziRJkiSpA16cSZIkSVIHvDiTJEmSpA54cSZJkiRJHfDiTJIkSZI64MWZJEmSJHXAizNJkiRJ6oAXZ5IkSZLUAS/OJEmSJKkDXpxJkiRJUge8OJMkSZKkDmxe5Ytt37792zP9/dtvT/35ggsumLS99ffsuVuPz15jjKH3sYj3/9577017U5IkSZLOKY6cSZIkSVIHvDiTJEmSpA6sNNZIrahfFumbsj2LEA5FFadGGaf875j3n8UuJUmSJJ0fHDmTJEmSpA54cSZJkiRJHVhbrHEoCjh19sRWLJDbsnLrNaa+3lAsU5IkSZKGOHImSZIkSR1Y28gZxSjU1DXKhh77zTffNMt8zIUXXnjaa2/efKpaxrynoZEzvvaQs1lvTZIkSdK5y5EzSZIkSeqAF2eSJEmS1IEuYo0hi/RlscbWJB+MEH799de1zO2t52aUkeWLL764ub31Pr766qu67eTJk83Xy+KVrcdKkiRJOn84ciZJkiRJHfDiTJIkSZI6sNJYYxZbbEX5xszQyJhhxAVj9sVSStm0aVPz+fh/W7ZsOe2x2cyNjDjy8V9++eUZ3ycjjtl6a8YZJUmSpPObI2eSJEmS1AEvziRJkiSpAyuNNQ4t6Jz9ndsZJ2zNsMjo4datW2uZ26+66qpavuKKK0opszMtHjt2rJaPHj1ay3zMiRMnajmikdlMkWMii0N1IEmSJOm7zZEzSZIkSeqAF2eSJEmS1IEuFqGOKN+YGRovuuiiWr7yyitrefv27aWUUm655Za67brrrqvlbdu21fKll15ay/GaX3zxRd12/PjxWmas8cMPPzxjOYs1Tok4jqkDSZIkSd89jpxJkiRJUge8OJMkSZKkDnQRawxZ5I8zNHIGxhtuuKGW9+zZU0op5a677qrbOCsjn/vTTz+t5Y8++ui017j66qtr+frrr6/lHTt21PI777xTy6+99loppZTDhw/XbZzZkWUuks0YZDDWKEmSJJ2fHDmTJEmSpA50MXLWGjHjCNMll1xSy5wEhCNZ99xzTymllF27dtVtn332WS0fOHCglt98881ajpEz4mvs3LmzljnBCCcmiUlDOKnI559/ftrzlpKPjDliJkmSJJ3fHDmTJEmSpA54cSZJkiRJHVhprJHRvVaUkdtY3rJlSy1zko+bb765WQ779u2r5SeffLKWOZnHl19+edrrMb542WWX1fKNN95Yy5yMJNY5O3ToUN2WTfzBNc9a9WG8UZIkSTo/OXImSZIkSR3w4kySJEmSOtDFbI2BkT6WGRG8/PLLa3n79u21HPHDgwcP1m3PP/98Lb/00ku1zFkVT548WUqZnX2R5SNHjtQyo4/btm2r5VgXjf/H9x+vUcpsrDFb123s3yVJkiR9dzhyJkmSJEkd8OJMkiRJkjrQRawxIoBZjG/Tpk21vHXr1lrmzI3xGC7+/MEHH9TysWPHark1YyJjiJxdkRhl5ELVsUg2n+Orr75qlvnajGuyLEmSJOn84xWBJEmSJHXAizNJkiRJ6sBKY42MLQ4twMwoI/8vm1UxMB546aWX1jJjiMePH6/lzZs3n/ZYxiW5IPU111xTy5w1Ml4zFrQupZQTJ07UMmOS2YyUkiRJks5vjpxJkiRJUgfWNiFIaxQtG1nLcEQqRsC49tntt99ey1u2bKllThoSo28xqUcps6NsO3furOXrr7++ljmyF+uYceQsm1TEtc0kSZIktThyJkmSJEkd8OJMkiRJkjqwtlhja0KQMY/lmmGffvppLcckH4w1Pvzww7W8Y8eOWj569Ohpzx3RxI1uvPHGWuZzf/bZZ7Uck39kUUbiZ3FtM0mSJEnBqwNJkiRJ6oAXZ5IkSZLUgZXGGqes68WI4Ndff13LjCQeOnSolmPdMa5LdvHFF9cyI4lffPHFac/HbXxtrqW2devW5vuIz8XZGuddw8y1zyRJkqTzkyNnkiRJktQBL84kSZIkqQMrjTVmszK2FqEmzqT48ccf1/Irr7xSy++9914ppZRt27bVba2FokuZjR9GZDJmXCxlNtbIWR4Zr+Rj4n+PHTt22raNr53N0NiqAxekliRJks4fjpxJkiRJUge8OJMkSZKkDqxttsahyB7/zv87cuRILTNmePjw4dO2MU6YLRAdszFm7+2OO+6o5c8//7yWObtjLEjNGRy5WDZlscUoG2WUJEmSzk+OnEmSJElSB7w4kyRJkqQOdDFbY+vvLDOemEUHI84YEcNSZmOIjC1u2bKlli+55JKZ/y9ldvFqxij52pyZ8fjx46WU2egkZ2Xka3MGydbMjVOin5IkSZK+Oxw5kyRJkqQOrHTkbMjQOmiltNcXK+XU2mWcqINl/t/WrVtrOUbMODqXTUbCkTq+duBI2ObNp6p23olQJEmSJJ0/HDmTJEmSpA54cSZJkiRJHegq1pjFF1lm/JBiO58jez5O/hHb+XdOGMLJQSI6ubEcUUT+X6yftvG5jS1KkiRJanHkTJIkSZI64MWZJEmSJHWgi1hjRP2yGCKjjFlEMKKKnDGR0ULOnsioYjyG/3f55ZfXMrdz9keuoTb0eoxAZvjZgxFISZIk6fzhyJkkSZIkdcCLM0mSJEnqQBexxoj0McaXzdZIrcdw25iFoLmwdOv/jh49Wsvvv/9+LTPWGM/N/6NsUetWlJGG/i5JkiTpu8ORM0mSJEnqgBdnkiRJktSBlcYas2jhlFkJuYB0a3ZH/p02bdrUfL1WJJHP+84779Ty/v37m485cuTIGV870/rcRhklSZKk85MjZ5IkSZLUAS/OJEmSJKkDK401DsUXx0T6GE/k42OxaC4EzQWkWaaIIvL/jh8/XssHDx487bEbyzGLI2dwnBpxDNnMjpIkSZK+2xw5kyRJkqQOrG2ds9aoUDayNmUiEW7jaFlr8hDiNo6cvfHGG7X87rvvNp/vxIkTpZRSjh07Vrdx/bQxI2Cttd6mTJQiSZIk6dzmyJkkSZIkdcCLM0mSJEnqQBfrnA3F/sbEHVuySTla/5fFGln+5JNPRr929nrZZzHCKEmSJJ3fHDmTJEmSpA54cSZJkiRJHbjAtbQkSZIkaf0cOZMkSZKkDnhxJkmSJEkd8OJMkiRJkjrgxZkkSZIkdcCLM0mSJEnqgBdnkiRJktQBL84kSZIkqQNenEmSJElSB7w4kyRJkqQOeHEmSZIkSR3w4kySJEmSOuDFmSRJkiR1wIszSZIkSeqAF2eSJEmS1AEvziRJkiSpA16cSZIkSVIHvDiTJEmSpA54cSZJkiRJHfDiTJIkSZI64MWZJEmSJHXAizNJkiRJ6oAXZ5IkSZLUAS/OJEmSJKkD/w+qKFa0Iu54NQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,4])\n",
    "n_digits = 9\n",
    "lastlayer = net.FeedForward(test[0][:10000])\n",
    "# plt.subplot(2,9,1)\n",
    "i=0\n",
    "while i < 10:\n",
    "    idx = np.random.randint(10000)\n",
    "    plt.subplot(2,9,i+1)\n",
    "    if(i == np.argmax(test[1][:10000][idx])):\n",
    "        plt.imshow(np.reshape(lastlayer[idx], [28,28]), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q2: BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know how to explain those simple chain rules in more details, as they are so obvious. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial E}{\\partial V} = \\sum_{i=1}^{\\tau}\\frac{\\partial C(y^i,t^i)}{\\partial V}\\\\\n",
    "Note\\ that\\ z^i\\ =\\ Vh^i\\ +\\ c\\\\\n",
    "and\\ y=\\sigma (z)\\\\\n",
    "=\\sum_{i=1}^{\\tau}\\frac{\\partial C(y^i,t^i)}{\\partial y^i}\\odot\\frac{dy^i}{dz^i}\\frac{\\partial z^i}{\\partial V}\\\\\n",
    "=\\sum_{i=1}^{\\tau}(\\frac{\\partial C(y^i,t^i)}{\\partial y^i}\\odot\\sigma'(z^i))(h^i)^T\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "s=Ux+Wh+b\\\\\n",
    "h=\\sigma (s)\\\\\n",
    "\\frac{\\partial E}{\\partial U} = \\sum_{i=1}^{\\tau}\\frac{\\partial E(y^i,t^i)}{\\partial h^i}\\odot\\frac{dh^i}{ds^i}\\frac{\\partial s^i}{\\partial U}\\\\\n",
    "=\\sum_{i=1}^{\\tau}(\\frac{\\partial E(y^i,t^i)}{\\partial h^i}\\odot\\sigma'(s^i))(x^i)^T\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is very similar to (b) but the only difference is that W only exists tau-1 times. So that every index of W should be smaller by 1 when compare to h's and s's indices\n",
    "$$\n",
    "\\begin{equation}\n",
    "s=Ux+Wh+b\\\\\n",
    "h=\\sigma (s)\\\\\n",
    "\\frac{\\partial E}{\\partial W} = \\sum_{i=1}^{\\tau - 1}\\frac{\\partial E(y^i,t^i)}{\\partial h^{i+1}}\\odot\\frac{dh^{i+1}}{ds^{i+1}}\\frac{\\partial s^{i+1}}{\\partial W}\\\\\n",
    "=\\sum_{i=1}^{\\tau -1}(\\frac{\\partial E(y^i,t^i)}{\\partial h^{i+1}}\\odot\\sigma'(s^{i+1}))(h^i)^T\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is very similar to (b) but the only difference is that the derivative of b is vector 1\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial E}{\\partial b} = \\sum_{i=1}^{\\tau}\\frac{\\partial E(y^i,t^i)}{\\partial h^i}\\odot\\frac{dh^i}{ds^i}\\frac{\\partial s^i}{\\partial b}\\\\\n",
    "=\\sum_{i=1}^{\\tau}(\\frac{\\partial E(y^i,t^i)}{\\partial h^{i}}\\odot\\sigma'(s^{i}))\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Q3: RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below creates two lists:\n",
    "  - `sentences`, and\n",
    "  - `next_chars`\n",
    "  \n",
    "Each list element represents a sequences of characters. There are 3 ways to represent a character:\n",
    "1. As a string, eg. `'b'`\n",
    "2. As an index to a character set, eg. `2`\n",
    "3. As a one-hot vector, eg. `[0, 0, 1, 0, ...]`\n",
    "\n",
    "The lists `sentences` and `next_chars` store the characters as indices (item 2 above). The utility functions\n",
    "  - `char2vec`\n",
    "  - `index2vec`\n",
    "  - `vec2char`\n",
    "  - `vec2index`\n",
    "  \n",
    "transform the characters between the 3 representations. You can also use the dictionaries `char_indices` and `indices_char` to convert between a string character and and index. The code below contains some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character set:  abcdefghijklmnopqrstuvwxyz (first char is a space)\n",
      "There are 27 characters in our character set\n",
      "Here is how you can view one of the samples:\n",
      "Sample input: [on the ori]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = open('origin_of_species.txt').read().lower()\n",
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0, \"\\0\") #Add newline character\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "# Let's simplify it by keeping only letters and spaces\n",
    "filt_idx = []\n",
    "for i in idx:\n",
    "    if i<=24:\n",
    "        filt_idx.append(2)\n",
    "    elif i>24:\n",
    "        filt_idx.append(i)\n",
    "blah = ''.join([indices_char[f] for f in filt_idx])\n",
    "text = re.sub(' +', ' ', blah)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('Character set: '+''.join(chars)+' (first char is a space)')\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "print('There are '+str(vocab_size)+' characters in our character set')\n",
    "\n",
    "''.join(indices_char[i] for i in idx[:70])\n",
    "\n",
    "def char2vec(c):\n",
    "    v = np.zeros(vocab_size)\n",
    "    v[char_indices[c]] = 1.\n",
    "    return v\n",
    "\n",
    "def index2vec(i):\n",
    "    v = np.zeros(vocab_size)\n",
    "    v[i] = 1.\n",
    "    return v\n",
    "\n",
    "def vec2index(v):\n",
    "    i = np.argmax(v)\n",
    "    return i\n",
    "\n",
    "def vec2char(v):\n",
    "    return indices_char[vec2index(v)]\n",
    "\n",
    "'''Form the dataset in sentences'''\n",
    "sentences_length = 10\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, 10000 - sentences_length + 1):\n",
    "    sentences.append(idx[i: i + sentences_length]) #Assume a sentence is made of X characters\n",
    "    next_chars.append(idx[i + 1: i + sentences_length + 1]) #Offset by 1 to the right for the target\n",
    "\n",
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])\n",
    "sentences.shape, next_chars.shape\n",
    "\n",
    "def read_sentence(idx):\n",
    "    return ''.join(indices_char[i] for i in idx)\n",
    "\n",
    "print('Here is how you can view one of the samples:')\n",
    "print('Sample input: ['+read_sentence(sentences[0])+']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return np.clip(z, a_min=0, a_max=None)  # ReLU\n",
    "    #return 1./(1+np.exp(-z))  # use this for logistic\n",
    "\n",
    "def sigma_primed(y):\n",
    "    return np.clip(np.sign(y), a_min=0, a_max=1)  # Derivative of ReLU\n",
    "    #return y*(1.-y)  # use this for logistic\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    denom = np.sum(ez)\n",
    "    return ez / denom\n",
    "\n",
    "def CrossEntropy(y, t):\n",
    "    return -sum(t*np.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Complete BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    \n",
    "    def __init__(self, dims, seq_length=10):\n",
    "        '''\n",
    "         Input:\n",
    "           dims is [X, H, Y], where the input has layer has X neurons, the\n",
    "                hidden layer has H neurons, and the output layer has Y neurons.\n",
    "           seq_length is how many steps to unroll the RNN through time\n",
    "                (this is the same as tau in the lecture notes)\n",
    "        '''\n",
    "        self.X, self.H, self.Y = dims\n",
    "        self.seq_length = seq_length\n",
    "        # Input layer\n",
    "        self.xs = [np.zeros(self.X) for x in range(seq_length)] # activity\n",
    "        # Hidden layer\n",
    "        self.hs = [np.zeros(self.H) for x in range(seq_length)] # activity\n",
    "        # Output layer\n",
    "        self.ys = [np.zeros(self.Y) for x in range(seq_length)] # activity\n",
    "        \n",
    "        # Connection weights\n",
    "        self.U = np.random.normal(size=[self.H, self.X])/np.sqrt(self.X) # input->hidden\n",
    "        self.W = np.random.normal(size=[self.H, self.H])/np.sqrt(self.H) # hidden->hidden\n",
    "        self.V = np.random.normal(size=[self.Y, self.H])/np.sqrt(self.H) # hidden->output\n",
    "        self.b = np.zeros(self.H) # biases for hidden nodes\n",
    "        self.c = np.zeros(self.Y) # biases for output nodes\n",
    "        \n",
    "    def ForwardTT(self, seq_in):\n",
    "        '''\n",
    "         i = ForwardTT(seq_in)\n",
    "        \n",
    "         Propagates the RNN forward through time, saving all the intermediate\n",
    "         states that will be needed for backprop through time (BPTT).\n",
    "        \n",
    "         Input:\n",
    "           seq_in is a vector of indecies, with self.seq_length elements.\n",
    "        \n",
    "         Output:\n",
    "           i is the index of the character predicted to follow the input.\n",
    "         \n",
    "         This method's main purpose is to update the states of the activites\n",
    "         in the time-unrolled network.\n",
    "        '''\n",
    "        self.xs[0] = index2vec(seq_in[0]) # convert to character vector\n",
    "        \n",
    "        # Starting input current for hidden nodes\n",
    "        ss = np.dot(self.U, self.xs[0]) + self.b\n",
    "        self.hs[0] = sigma(ss)  # Activation of hidden nodes\n",
    "        \n",
    "        # Input current for output nodes\n",
    "        zs = np.dot(self.V, self.hs[0]) + self.c\n",
    "        self.ys[0] = softmax(zs)  # Activation of output nodes\n",
    "        \n",
    "        # Now process forward in time\n",
    "        for i in range(1, self.seq_length):\n",
    "            self.xs[i] = index2vec(seq_in[i])  # input vector\n",
    "            \n",
    "            # Input current for hidden nodes, including recurrent connections\n",
    "            ss = np.dot(self.U, self.xs[i]) + np.dot(self.W, self.hs[i-1]) + self.b\n",
    "            self.hs[i] = sigma(ss)  # Activation\n",
    "            \n",
    "            # Input current for output nodes\n",
    "            zs = np.dot(self.V, self.hs[i]) + self.c\n",
    "            self.ys[i] = softmax(zs)  # Activation\n",
    "            \n",
    "        # Might as well output the final state of the output\n",
    "        return vec2index(self.ys[-1])\n",
    "    \n",
    "    \n",
    "    def BPTT(self, seq_in, seq_out):\n",
    "        '''\n",
    "         BPTT(seq_in, seq_out)\n",
    "         \n",
    "         Performs backprop through time on one sample given by the input and\n",
    "         output sequence.\n",
    "         \n",
    "         Input:\n",
    "           seq_in is a vector of indices specifying the input sequence of\n",
    "                   characters.\n",
    "           seq_out is a vector of indices specifying the output sequence of\n",
    "                   characters. Typically, seq_out is the same as seq_in, but\n",
    "                   shifted by 1 character.\n",
    "         \n",
    "         Output:\n",
    "           None, but the connection weights and biases are updated.\n",
    "        '''\n",
    "        # Initialize gradients to zero\n",
    "        self.dEdV = np.zeros(np.shape(self.V))\n",
    "        self.dEdW = np.zeros(np.shape(self.W))\n",
    "        self.dEdU = np.zeros(np.shape(self.U))\n",
    "        self.dEdb = np.zeros(np.shape(self.b))\n",
    "        self.dEdc = np.zeros(np.shape(self.c))\n",
    "        \n",
    "        # ===================\n",
    "        # ===================\n",
    "        # =  YOUR CODE HERE =\n",
    "        # ===================\n",
    "        # ===================\n",
    "        dEdz = []\n",
    "        ## Note that we don't have sigma prime here because Porf Orchard said on piazza that it was simply (y-t)\n",
    "        for i in range(self.seq_length):\n",
    "            dEdz.append(self.ys[i] - index2vec(seq_out[i]))\n",
    "        dEds = [0]*self.seq_length\n",
    "        dEds[-1] = sigma_primed(self.hs[-1]) * (self.V.T@dEdz[-1])\n",
    "        for i in range(self.seq_length - 2, -1, -1):\n",
    "            dEds[i] = sigma_primed(self.hs[i])*((self.V.T@dEdz[i])+(self.W.T@dEds[i+1]))\n",
    "        for i in range(self.seq_length):\n",
    "            self.dEdb += dEds[i]\n",
    "            self.dEdc += dEdz[i]  \n",
    "            self.dEdV += np.array([dEdz[i]]).T@np.array([self.hs[i]])\n",
    "            self.dEdU += np.array([dEds[i]]).T@np.array([self.xs[i]])\n",
    "            if(i != self.seq_length-1):\n",
    "                self.dEdW += np.array([dEds[i+1]]).T@np.array([self.hs[i]])\n",
    "            \n",
    "       \n",
    "    def Generate(self, n=1):\n",
    "        '''\n",
    "         c = Generate(n=1)\n",
    "         \n",
    "         Runs the RNN from the last state after running ForwardTT, outputting\n",
    "         the next n characters.\n",
    "         \n",
    "         Input:\n",
    "           n is the number of characters you want to predict\n",
    "           \n",
    "         Output:\n",
    "           c is a string of n characters\n",
    "        '''\n",
    "        y = self.ys[-1]  # Final output of ForwardTT\n",
    "        c = vec2char(y)  # Convert it to a character string\n",
    "        h = self.hs[-1]  # Starting with last hidden state...\n",
    "        # Loop forward in time\n",
    "        # (no need to record states, since we won't be doing BPTT)\n",
    "        for nn in range(n-1):\n",
    "            x = copy.copy(y)  # Use last output as next input\n",
    "            \n",
    "            # Input current for hidden nodes\n",
    "            s = np.dot(self.U, x) + np.dot(self.W, h) + self.b\n",
    "            h = sigma(s)  # Activation\n",
    "            \n",
    "            # Input current for output nodes\n",
    "            z = np.dot(self.V, h) + self.c\n",
    "            y = softmax(z)  # Activation\n",
    "            \n",
    "            # And add the next character to our output string\n",
    "            c += vec2char(y)\n",
    "            \n",
    "        return c\n",
    "            \n",
    "    def Evaluate(self, train_in, train_out):\n",
    "        '''\n",
    "         loss = Evaluate(train_in, train_out)\n",
    "         \n",
    "         Evaluates the network on the supplied dataset.\n",
    "         \n",
    "         Input:\n",
    "           train_in is a list of input sequences (see ForwardTT for format of input)\n",
    "           train_out is the corresponding list of output sequences\n",
    "           \n",
    "         Output:\n",
    "           loss is the average cross entropy\n",
    "        '''\n",
    "        val = 0.\n",
    "        for x, t in zip(train_in, train_out):\n",
    "            self.ForwardTT(x)\n",
    "            for i in range(self.seq_length):\n",
    "                val += CrossEntropy(self.ys[i], index2vec(t[i]))\n",
    "        return val/len(train_in)\n",
    "            \n",
    "    def Train(self, train_in, train_out, kappa=0.05, epochs=1):\n",
    "        '''\n",
    "         Train(train_in, train_out, kappa=0.05, epochs=1)\n",
    "         \n",
    "         Performs epochs of gradient descent, performing BPTT after each sample.\n",
    "         \n",
    "         Input:\n",
    "           train_in and train_out is the training dataset\n",
    "           kappa is the learning rate\n",
    "           epochs is the number of times to go through the dataset\n",
    "           \n",
    "         Output:\n",
    "           None, but the connection weights and biases are updated\n",
    "        '''\n",
    "        # Loop over epochs\n",
    "        for e in range(epochs):\n",
    "            \n",
    "            # Shuffle the training data\n",
    "            data_shuffled = list(zip(train_in, train_out))\n",
    "            np.random.shuffle(data_shuffled)\n",
    "            \n",
    "            for x, t in data_shuffled:\n",
    "                self.ForwardTT(x)  # Forward through time\n",
    "                self.BPTT(x, t)    # Backprop through time\n",
    "                # Note that BPTT starts by resetting the gradients to zero.\n",
    "                \n",
    "                # Apply update to connection weights and biases\n",
    "                self.V -= kappa*self.dEdV\n",
    "                self.U -= kappa*self.dEdU\n",
    "                self.W -= kappa*self.dEdW\n",
    "                self.b -= kappa*self.dEdb\n",
    "                self.c -= kappa*self.dEdc\n",
    "\n",
    "            print('Epoch '+str(e)+', Loss = '+str(self.Evaluate(train_in, train_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (b) Create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "net = RNN(dims = [27, 400, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (c) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 19.050024241272844\n",
      "Epoch 1, Loss = 16.430305238280358\n",
      "Epoch 2, Loss = 14.627750681441901\n",
      "Epoch 3, Loss = 13.184027250475413\n",
      "Epoch 4, Loss = 11.858591427497291\n",
      "Epoch 5, Loss = 11.196167879670066\n",
      "Epoch 6, Loss = 10.446159409778659\n",
      "Epoch 7, Loss = 10.078525277698576\n",
      "Epoch 8, Loss = 9.40371178642847\n",
      "Epoch 9, Loss = 9.250558881945375\n",
      "Epoch 10, Loss = 8.952118981387818\n",
      "Epoch 11, Loss = 8.675863221243807\n",
      "Epoch 12, Loss = 8.543312573465013\n",
      "Epoch 13, Loss = 8.389521157269407\n",
      "Epoch 14, Loss = 8.349193511337713\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "net.Train(sentences, next_chars, kappa = 0.001, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You might opt to have more than one train command, using different\n",
    "# learning rates and numbers of epochs. Each one builds on the results\n",
    "# from the last run.\n",
    "#net.Train(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (d) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:      n introduc\n",
      "Prediction: n introduction \n",
      "Actual:     n introduction when \n"
     ]
    }
   ],
   "source": [
    "# A sample continuation.\n",
    "n = 38\n",
    "b = net\n",
    "b.ForwardTT(sentences[n])\n",
    "blah = read_sentence(sentences[n])\n",
    "print('Input:      '+blah)\n",
    "print('Prediction: '+blah+b.Generate(5))\n",
    "print('Actual:     '+blah+read_sentence(sentences[n+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harles dar\n",
      "harles darwin i trri\n"
     ]
    }
   ],
   "source": [
    "blah = 'harles dar'\n",
    "x = [char_indices[c] for c in blah]\n",
    "b.ForwardTT(x)\n",
    "print(blah)\n",
    "print(blah+b.Generate(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jackpot time:9392\n",
      "my accuracy:94.02342577%\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "counter = 0\n",
    "for i in range(len(sentences)):\n",
    "    net.ForwardTT(sentences[i])\n",
    "    prediction = net.Generate()\n",
    "    if prediction == vec2char(index2vec(next_chars[i][-1])):\n",
    "        counter += 1\n",
    "\n",
    "print(\"jackpot time:\"+str(counter))\n",
    "print(\"my accuracy:\"+str(round(counter/len(sentences),10)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
